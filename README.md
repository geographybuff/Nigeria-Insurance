# Nigeria-Insurance
Check out Nigeria Insurance.ipynb for a Jupyter Notebook with the commented source code. 

Winning solution for 2019 Dar Machine Learning Hackathon, with @mtuchidev. Original challenge at https://zindi.africa/competitions/data-science-nigeria-2019-challenge-1-insurance-prediction
Since we’re predicting a binary variable (whether or not a claim was filed), we used a combination of logistic regression and Naive Bayes formulas. We used logistic regression for the continuous value of building dimension, and Naive Bayes for categorical values like Settlement and Building Type. Logistic regression and NB mesh well since the goal of both is to return a probability based on a parameter. You can then multiply the probabilities to get a combined probability. Combinatorial probability is based on Bayes’ Theorem, but it’s not necessary to fill out the full formula if you’re calculating the same parameters for every datapoint and thus the two prior probabilities on the right side never change. If you don’t fill out the full formula, you won’t get probabilities on a 0-1 scale, but a higher number will still indicate a higher probability. This is all you need to set a percentile threshold. Since the evaluation metric for this competition was Area under the ROC Curve, your score is highly sensitive on the threshold you set. While 22% of the train set were 1’s, we found the sweet spot at around 24%: predicting the 24% most likely buildings as 1’s and the rest as 0’s. The reason why the top 24% works better than the top 22% is because false negatives were hurting us more than false positives near the threshold, because of the evaluation metric. 
